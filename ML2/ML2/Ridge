import numpy as np 
from sklearn.cluster import KMeans
#from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, RidgeCV
  
#cdata collection
X_train = np.load('X_train_regression2.npy')
Y_train = np.load('y_train_regression2.npy')
X_test = np.load('X_test_regression2.npy')


#preprocessing
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

combined_data = np.hstack((X_train_scaled, Y_train.reshape(-1, 1)))

#apply K-Means 
kmeans = KMeans(n_clusters=2, random_state=0).fit(combined_data) #kmeans kan ikke brukes, annen metode for Ã¥ finne outliers og lage clusters slik
 
#datapoint index of each cluster 
idx_cluster1 = np.where(kmeans.labels_ == 0)
idx_cluster2 = np.where(kmeans.labels_ == 1)

#predefined potential alpha values
alphas = [0.001, 0.1, 1, 10, 14, 15, 16, 20, 100]

#RidgeCV 
ridge_cv1 = RidgeCV(alphas=alphas, store_cv_values=True).fit(X_train_scaled[idx_cluster1], Y_train[idx_cluster1])
best_alpha_cluster1 = ridge_cv1.alpha_

ridge_cv2 = RidgeCV(alphas=alphas, store_cv_values=True).fit(X_train_scaled[idx_cluster2], Y_train[idx_cluster2])
best_alpha_cluster2 = ridge_cv2.alpha_


#train two linear models
model1 = Ridge(alpha=best_alpha_cluster1).fit(X_train_scaled[idx_cluster1], Y_train[idx_cluster1])
model2 = Ridge(alpha=best_alpha_cluster2).fit(X_train_scaled[idx_cluster2], Y_train[idx_cluster2])


#prediction
y_predictions_model1 = model1.predict(X_test_scaled)
y_predictions_model2 = model2.predict(X_test_scaled)


ans = np.column_stack((y_predictions_model1, y_predictions_model2))

np.save("model_prediction", ans)
